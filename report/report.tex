\documentclass[a4paper]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{amsmath}

\author{Gautier \textsc{Colajanni}, Cédric \textsc{Jezequel},\\ Julien \textsc{Marcou}, Pierre \textsc{Poilane}, Paul \textsc{Rivière}, Kévin \textsc{Thek}}

\title{Rapport de projet Acquisition de Connaissances \\ Authorship Attribution}

\begin{document}

\maketitle

\section{Introduction}
Notre projet porte sur la classification automatisée de documents textuels en fonction de leur auteur. Nous allons expérimenter plusieurs techniques de classification et comparer leurs performances respectives.

La première technique consiste en une sélection de critères de discrimination uniquement basée sur les fréquences des termes utilisés par les auteurs. La deuxième méthode va s'orienter sur la nature des mots employé et la construction des phrases pour identifier l'auteur par son style.

\todo{Qui et Quoi ?}

\section{Détails techniques}

Notre projet portant sur un nombre d'heures limités et souhaitant obtenir des résultats rapidement sans avoir à capitaliser des connaissances sur un langage particulier nous avons fait le choix de développer au maximum en PHP. Ce choix ce justifie par le fait que ce langage est accessible en ligne de commande, est assez performant lorsqu'il s'agit de traiter avec du texte et que la majorité de l'équipe a déjà travailler avec ce qui permettait d'être familier avec ces structures de données et son fonctionnement.

L'organisation autour des sources s'est fait naturellement à l'aide du gestionnaire de version git maintenant maîtrisé par une majorité d'étudiant ayant compris l'intérêt d'un tel outil au sein de projets de toute taille.

\section{Méthode 1 : Term-frequency criterion}
Une première méthode consiste à classifier un document en fonction de la présence de certains mots dans ce texte. Il va s'agir ainsi de construire un classifieur en utilisant un ensemble d'apprentissage, et de trouver la classe qui correspond au mieux à un document faisant partie de l'ensemble de test.

\subsection{Création de la matrice de classification}
Le but ici est de discriminer les auteurs en générant des critères de comparaison. À partir de l'ensemble d'apprentissage, nous allons extraire les mots les plus pertinents pour chaque auteur. Nous allons pour cela utiliser un critère de fréquence de terme rapportée à l'ensemble du corpus (c'est-à-dire pour tous les documents de tous les auteurs).

Tout d'abord, nous avons utilisé une liste de \textit{stopwords} pour retirer les mots trop communs des articles. Pour alléger le traitement, nous avons également opté pour éliminer tous les mots de 2 lettres ou moins. 

La métrique utilisée est \[ tfc_{ij} = tf_{ij} \times idf\] avec $tf_{ij}$ est la fréquence d'apparition d'un terme $t_{ij}$ dans l'ensemble du corpus de l'auteur $j$.\todo{à vérifier} $idf$ est la fréquence inverse du document et s'exprime ainsi : \[idf = \log \frac{|\Omega|}{df(t_{i})} \] avec $|\Omega|$ le nombre de documents dans le corpus et $df(t_{i})$ le nombre de documents dans lequel apparait le terme $t_{i}$.

Après génération de cette métrique, vu le grand nombre de termes restants, nous avons décidé d'appliquer un filtre pour ne garder que les plus significatifs. Après plusieurs tests manuels, la valeur de seuil $T = $ \todo{à reporter} a été décidée, car procurant un nombre réduit mais néanmoins intéressant de termes.

Au final nous sommes arrivés à une matrice probabilistique contenant les métriques que nous avons calculés durant cette phase et qui nous servira pour la partie suivante. Cette matrice se présente ainsi :

\[M=\bordermatrix{
&A_{1}&\cdots&A_{j}&\cdots&A_{n}\cr
t_{1}& tfc_{11} & \cdots & tfc_{1j} & \cdots & tfc_{1n} \cr
\vdots&\vdots&\ddots&\vdots&\ddots&\vdots\cr
t_{i}& tfc_{i1} & \cdots & tfc_{ij} & \cdots & tfc_{in} \cr
\vdots&\vdots&\ddots&\vdots&\ddots&\vdots\cr
t_{m}& tfc_{m1} & \cdots & tfc_{mj} & \cdots & tfc_{mn} \cr
}\]
\subsection{Classification d'un document}

\section{Méthode 2 : Part-of-Speech analysis}

Afin de parvenir à réaliser une analyse sur un corpus complet, il nous a paru pertinent de nous appuyer sur la nature des mots et leur agencement plutôt que sur leur signification. Pour parvenir à exploiter les corpus de manière satisfaisante, nous avons opté par l'emploi de tag (Part-of-Speech) fourni par l'outil Tree Tagger\footnote{http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/}.

Nous avons mis en place plusieurs sources d'informations que nous pensions, au premier abord, pertinente pour identifier des auteurs. Ces sources s’appuient sur la fréquence d'apparition des tags, sur l'étude des transitions (quel tag est suivi de quel autre tag) ainsi que sur les n-grams que nous détaillerons ensuite.

\todo{Ajouter exemple de transformation d'une phrase en tag}


\subsection{Normalisation des textes}

La normalisation des textes se fait d'une manière très simple et efficace grâce à un script bash créant un fichier contenant la liste des tags par ordre d'apparition et ce pour chaque auteur. C'est cette source de donnée qui est utilisée pour les outils suivants. 

\subsection{Premières métriques}

Souhaitant réaliser une identification des textes du corpus proposé, nos efforts se sont concentrés sur des façons de faire ressortir les disparités des textes par auteur. En considérant que chaque auteur a une façon d'écrire qui lui est propre, nous nous sommes demandé quelles caractéristiques nous pouvions employer afin d'identifier de manière correcte un nouveau texte.

\subsubsection{Classification par étude de fréquence}

Cette première méthode consistait à simplement compter la fréquence d'apparition des tags reportés et ce, de manière globale, pour chaque auteur. Cette analyse a l'avantage de se faire rapidement mais ne donne malheureusement pas de résultat probant. Néanmoins, cette phase nous a permis de prendre en main les données qui étaient à notre disposition et d'essayer de comprendre ce qui pouvait être discriminant dans un texte ou non.

\todo{Gautier:Faire la comparaison avec TOUT le corpus}

\todo{citer méthodologie de test et résultats obtenus}

\subsubsection{Longueur des paragraphes}

Partant de ce premier échec à identifier les textes par la fréquence d'apparition des tags, nous avons pensé qu'il pouvait être intéressant d’agréger cette source d'information trop vague à d'autres métriques afin d'obtenir une réponse plus précise. Nous avons donc ajouté deux éléments : le nombre de mot par ligne en moyenne et l'écart-type pour cette même mesure et ce pour chaque auteur.

Par l'étude de cette métrique, nous pensions avoir décelé un patron intéressant pour l'étude de textes. Mais au final, cette métrique s'est révélée être très décevante tant elle était constante d'un auteur à un autre. On peut voir sur la \textsc{figure \ref{WPL}} qu'il n'y a pas de différence réellement exploitable.
				
\begin{figure}[hbtp]
\centering
\includegraphics[width=11cm]{fig/WPL.png}
\caption{Mots par paragraphe}
\label{WPL}
\end{figure}

À ce stade, nous avons décidé de laisser de côté ces analyses trop simples. En effet, ces analyses se concentrant uniquement sur un élément particulier, les résultats ne peuvent être que dilués dans l'ensemble des données.

\todo{Changer : montrer que ce n'est pas discriminant}

\subsection{Étude des transitions}

Afin de parvenir à identifier les auteurs de nos textes, nous avons pensé qu'il serait plus judicieux de nous intéresser aux schémas apportés par les transitions. En effet, un auteur utilisant beaucoup de qualificatifs ou ayant une manière personnelle d'exprimer les choses pourra potentiellement être identifié par ce biais là. C'est à ce moment là que nous nous sommes réellement posé la question de la pertinence de nos précédentes métriques. En effet, nos métriques précédentes ne sont-elles pas intrinsèques au langage ?

Par l'étude de la transition, nous avons souhaité construire assez simplement une matrice normalisée représentant tous les tags proposés par Tree Tagger et nous permettant de savoir si le tag X est suivi du tag Y et ce, à quel fréquence (par rapport au corpus de référence dans son intégralité).

\todo{étude de la matrice avec eigenvalues}

\subsection{Déploiement de la méthode des n-grams}

L'étude des transitions nous ayant posé quelques problèmes pour trouver une manière élégante de comparer des matrices de transitions, nous nous sommes penchés sur une méthode un peu plus générique et nous offrant peut-être un peu plus de souplesse quant à sa configuration. Toujours dans l'idée d'identifier nos auteurs par leur façon de tourner leurs phrases, cette méthode nous permet de choisir la longueur de nos «~grams~» et d'en ressortir un résultat assez simplement.

Cette méthode nous permet de tirer partis de l'ordre dans lequel sont écris les mots utilisés par nos auteurs. Après avoir passé l'ensemble de notre corpus de test sous forme de tag, avec le même outil que précédement (Tree Tagger), nous analysons les différents enchainements de tags repérés dans nos fichiers. Pour un 2-grams, nous nous occuperons seulement des enchainement de 2 tags, pour un 3-grams, des enchainements de 3 tags, etc ...

Pour se faire, nous prenons un à un chacun des enchainements que nous rencontrons, comptabilisons son nombre d'occurrence dans l'ensemble des articles d'un auteur, puis compilons ces résultats. L'ensemble de ces calculs et mises en formes sont réalisés à l'aide de script pearl, simplifiant la lecture et l'écriture au sein de fichiers .txt et .csv.

Suite à cette première analyse, un fichier .csv récapitulatif des fréquences d'apparition de ces suite est généré. Ce dernier, classé par auteurs, est ensuite comparé à notre fichier à classifier : est alors réalisé une comparaison point à point de l'ensemble des combinaisons liées à un auteur, calculons son taux de "matching" et sortons l'auteur ayant le plus fort taux d'affiliation et donc, le plus probable pour ce texte. 

Cette méthode est tout de fois assez lourde puisqu'elle requiert une bonne dizaine de minute pour s'exécuter intégralement bien que déjà placée totalement en mémoire (sur un système de fichier tmpfs). Néanmoins, jusqu'à présent, seulement cette méthode a réussi à nous montrer des résultats. À nos yeux bien décevants, mais tout de même réjouissants car les premiers à approcher les 25\% de réussite.

\todo{expliquer plus en détail le cheminement des données et comment les données sont traitées}

\section{Comparaison de performance}

Que ce soit la première méthode ou la seconde, nos résultats nous paraissent assez décevants. En effet, il nous est impossible d'identifier ne serait-ce que 50\% des textes convenablement. Néanmoins, voici un tableau récapitulant les performances obtenues sur les différents stades de deux méthodes développées.

\todo{Insérer un tableau comparatif}

\section{Conclusion}

\todo{Identification de nos erreurs, bilan technique et péda}

\end{document}
